# AI Recipe Shoplist Crawler - Configuration
# =================================================================
# This file contains all configuration for the AI Recipe Shoplist Crawler
# Copy this file to .env and configure the provider you want to use

# =================================================================
# GENERAL APPLICATION SETTINGS
# =================================================================

# Web Application Settings
PORT=8000
HOST=0.0.0.0

# =================================================================
# LOGGING CONFIGURATIONS
# =================================================================
LOG_LEVEL=DEBUG
LOG_DEBUG_ENABLED=true
LOG_FILE_ENABLED=true
LOG_FILE_PATH=/tmp/ai_shopping/logs/app.log
LOG_MAX_LENGTH=0
LOG_CHAT_MESSAGE_MAX_LENGTH=0
# LOG_CHAT_MESSAGE_SINGLE_LINE=true
# LOG_CHAT_FULL_RESPONSES=false

# =================================================================
# AI PROVIDER CONFIGURATIONS
# =================================================================
# AI Provider Selection (choose one: github, openai, azure, ollama)
PROVIDER=github
# PROVIDER_CHAT_ENABLED=false


# TIKTOKEN_MODEL=gpt-4o
TIKTOKEN_ENCODER=o200k_base

# -----------------------------------------------------------------
# GITHUB MODELS PROVIDER
# -----------------------------------------------------------------
# Free tier with conservative rate limits
# Get your token at: https://github.com/settings/tokens

GITHUB_TOKEN=your_github_token_here
GITHUB_MAX_TOKENS=4000
GITHUB_MODEL=gpt-4o-mini
GITHUB_API_URL=https://models.inference.ai.azure.com
GITHUB_MODEL_TIMEOUT=30
GITHUB_MAX_RETRIES=5

# -----------------------------------------------------------------
# OPENAI PROVIDER
# -----------------------------------------------------------------
# Paid service with higher rate limits
# Get your API key at: https://platform.openai.com/api-keys

OPENAI_API_KEY=your_openai_api_key_here
OPENAI_MODEL=gpt-4o-mini
OPENAI_MAX_TOKENS=2000
OPENAI_TEMPERATURE=0.1

# -----------------------------------------------------------------
# AZURE OPENAI PROVIDER
# -----------------------------------------------------------------
# Enterprise service with highest rate limits
# Configure in Azure Portal: https://portal.azure.com

AZURE_OPENAI_API_KEY=your_azure_openai_api_key_here
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_VERSION=2024-02-01
AZURE_OPENAI_DEPLOYMENT_NAME=gpt-4o-mini

# -----------------------------------------------------------------
# OLLAMA PROVIDER (LOCAL)
# -----------------------------------------------------------------
# Local LLM service - no API key required
# Install Ollama: https://ollama.ai

OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b
OLLAMA_TIMEOUT=120

# =================================================================
# RETRY & RATE LIMITING CONFIGURATION
# =================================================================
# Tenacity-based retry configuration for all providers

# -----------------------------------------------------------------
# GLOBAL RETRY DEFAULTS
# -----------------------------------------------------------------
# These serve as fallback values when provider-specific settings are not defined

DEFAULT_MAX_RETRIES=3              # Number of retry attempts for failed requests
DEFAULT_BASE_DELAY=1.0             # Base delay in seconds for exponential backoff
DEFAULT_MAX_DELAY=60.0             # Maximum delay cap in seconds
DEFAULT_RETRY_MULTIPLIER=2.0       # Exponential backoff multiplier (1s → 2s → 4s → 8s...)
DEFAULT_RPM_LIMIT=15               # Default requests per minute limit

# -----------------------------------------------------------------
# GITHUB MODELS RETRY SETTINGS
# -----------------------------------------------------------------
# Conservative settings due to free tier limitations

GITHUB_MAX_RETRIES=3
GITHUB_BASE_DELAY=1.0
GITHUB_MAX_DELAY=60.0
GITHUB_RETRY_MULTIPLIER=2.0
GITHUB_RPM_LIMIT=15               # Conservative limit for free tier

# -----------------------------------------------------------------
# OPENAI RETRY SETTINGS
# -----------------------------------------------------------------
# Moderate settings for paid tier

OPENAI_MAX_RETRIES=3
OPENAI_BASE_DELAY=1.0
OPENAI_MAX_DELAY=60.0
OPENAI_RETRY_MULTIPLIER=2.0
OPENAI_RPM_LIMIT=60               # Higher limits for paid service

# -----------------------------------------------------------------
# AZURE OPENAI RETRY SETTINGS
# -----------------------------------------------------------------
# Higher settings for enterprise tier

AZURE_MAX_RETRIES=3
AZURE_BASE_DELAY=1.0
AZURE_MAX_DELAY=60.0
AZURE_RETRY_MULTIPLIER=2.0
AZURE_RPM_LIMIT=120              # Highest limits for enterprise service

# -----------------------------------------------------------------
# OLLAMA RETRY SETTINGS (LOCAL)
# -----------------------------------------------------------------
# Aggressive settings for local service

OLLAMA_MAX_RETRIES=3
OLLAMA_BASE_DELAY=0.5            # Faster retries for local service
OLLAMA_MAX_DELAY=30.0            # Lower max delay for local service
OLLAMA_RETRY_MULTIPLIER=1.5      # Gentler backoff for local service
OLLAMA_RPM_LIMIT=0               # No rate limiting for local service (0 = unlimited)

# =================================================================
# WEB SCRAPER CONFIGURATION
# =================================================================
WEB_SCRAPER_HTML_TO_TEXT=true                        # Convert HTML content to text after extraction

# =================================================================
# BLOB STORAGE CONFIGURATION
# =================================================================
# BLOB_ENABLED=false           # Enable or disable blob storage
BLOB_BASE_PATH=/tmp/ai_shopping

# =================================================================
# CACHE CONFIGURATION
# =================================================================
# CACHE_ENABLED=false         # Enable or disable caching
CACHE_TTL=3600              # Cache TTL in seconds (1 hour)
CACHE_MAX_SIZE=10485760     # Maximum content size in bytes (10MB)
CACHE_AI_TTL=300            # AI response cache TTL in seconds (5 minutes)

# =================================================================
# DB CONFIGURATION
# =================================================================
DB_PATH=/tmp/ai_shopping/db/shoplist.db
# DB_ENABLED=false      # Enable or disable database storage

# =================================================================
# RAPID API CONFIGURATION
# =================================================================
# For api calls to Rapid API services to fetch grocery product data (Coles)
RAPID_API_KEY=your_rapid_api_key_here